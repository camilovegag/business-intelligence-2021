{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Buisness Intelligence - Sheet 3 </h1>\n",
    "<h3> Camilo Andrés Vega Agudelo - 0000163913</h3>\n",
    "<h3> Juan Felipe Herrera Rincon - 0000156342</h3>\n",
    "<h3> Johan Nicolas Imbachi Nino - 0000179756 </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2.1 - by Juan Felipe Herrera Rincon ( also 1.1 )\n",
    "<b>a)</b> Write a function binarizeCategoricalAttributeVector(column) that takes a categorical attribute vector (do not assume a categorical Pandas type) and re- turns an n × m dimensional numpy array, where m is the number of categorical values occurring in the column and n is the length of the original column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarizeCategoricalAttributeVector(column):\n",
    "    copy = column.copy()\n",
    "    df = pd.DataFrame(copy)\n",
    "    categorias = df[0].unique()\n",
    "    columns = len(categorias)\n",
    "    vector=[]\n",
    "    cont=0\n",
    "    for categoria in categorias:\n",
    "        for valor in df[0]:\n",
    "            if(categoria == valor):\n",
    "                fila = np.zeros(columns,dtype=int)\n",
    "                fila[cont]=1\n",
    "                vector.append(fila)\n",
    "        cont=cont+1\n",
    "        \n",
    "    matrix = np.array(vector)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>b)</b> Then write a function getCategoricalAttributes(df) that returns a list of col- umn names of a Pandas DataFrame that contain non-numeric values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCategoricalAttributes(df):\n",
    "    return list(df.select_dtypes(exclude=[np.number]).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>c)</b> Finally, write a function readFrameAsMatrix(df) to convert a given DataFrame into a purely numeric nd array, expanding categorical features to binary vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFrameAsMatrix(df):\n",
    "    catAttr = getCategoricalAttributes(df)\n",
    "    for attr in catAttr:\n",
    "        vectors = binarizeCategoricalAttributeVector(df[attr].values)\n",
    "        df = pd.concat([df, pd.DataFrame(vectors)], axis=1)\n",
    "        df.drop([attr],axis=1, inplace=True)\n",
    "    \n",
    "    matrix = df.values\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2.2\n",
    "<b>a)</b> Write a function discretizeBasedOnThresholds(column, thresholds, names=None)\n",
    "that takes a vector of observations, the desired thresholds and optionally names for\n",
    "the bins; if no names are given, name the bins c0,c1,... The first bin contains all\n",
    "instances with values at most the lowest threshold, and the last bin contains all\n",
    "instances with values greater than the biggest threshold. Hence, the number of\n",
    "bins is the number of thresholds + 1. The function should return a vector with the\n",
    "discretized values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretizeBasedOnThresholds(column, thresholds, names=None):\n",
    "    creditsSorted = credits.sort_values(by=[column])\n",
    "    minValue = credits[column].min()\n",
    "    maxValue = credits[column].max()\n",
    "    \n",
    "    #Verify Sorted Data is working\n",
    "    #print (creditsSorted)\n",
    "    \n",
    "    for i in thresholds:\n",
    "        maxLimit = i\n",
    "        df= creditsSorted.loc[(creditsSorted['age']>= minValue) & (creditsSorted['age']< maxLimit)]\n",
    "        minValue = i\n",
    "        print (df)\n",
    "        \n",
    "        #Dataframes correct but missing the last one, between the last limit of the threshold\n",
    "        #And the maximum value of the DF... Other DF are ok, Sorted and Printed in different DF's\n",
    "        #Fix the bins names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>b)</b> Write functions discretizeEqualLength(column, k, names = None) and\n",
    "discretizeEqualFrequency(column, k, names = None) that convert a numeric\n",
    "attribute vector into a discrete attribute vector, applying the respective technique\n",
    "for a specified number of bins or frequency. The parameter k is for the number of\n",
    "bins. Use the above function to realize these two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretizeEqualLength(column, k, names=None):\n",
    "    \n",
    "    \n",
    "    creditsSorted = credits.sort_values(by=[column])\n",
    "    minimumValue = credits[column].min()\n",
    "    upperLimit = credits[column].max()\n",
    "    equalLength = (upperLimit-minimumValue)/k\n",
    "    \n",
    "    for i in range (1,k+1):\n",
    "        #from upper limit to lower subsctracting the equals value\n",
    "        lowerLimit = upperLimit\n",
    "        upperLimit = lowerLimit-equalLength\n",
    "        \n",
    "        rg = (lowerLimit, upperLimit)\n",
    "        \n",
    "        print(rg[::-1])\n",
    "    \n",
    "    #Discretizing values in tuples, equal length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2.3 - by Camilo Andrés Vega Agudelo\n",
    "<li><p><b>a)</b> Write a function <b>getContingencyTable(M)</b> that receives a 2D numpy array with two columns and computes a table containing the <i>absolute</i> observed frequenties of the pairs of occuring values.</p></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContingencyTable(M):\n",
    "    df = pd.DataFrame(M).sort_values(0).reset_index(drop=True)\n",
    "    index = df[0].unique()\n",
    "    head = df[1].unique()\n",
    "    full_data = []\n",
    "    data = []\n",
    "\n",
    "    for x in index:\n",
    "        row = df[df[0] == x]\n",
    "        data = []\n",
    "\n",
    "        for y in head:\n",
    "            data.append(np.count_nonzero(np.where(row == y)[1]))\n",
    "        full_data.append(data)\n",
    "    \n",
    "    contingency_table = pd.DataFrame(full_data)\n",
    "    \n",
    "    return(contingency_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><p><b>b)</b> Write a function <b>computeExpectedOccurrences(ct)</b> that receives a contingency table and computes a table containing, for each pair of values, the number of occurences one would expect given independency of the attributes.</p></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeExpectedOccurrences(ct):\n",
    "    array = ct.to_numpy()\n",
    "    column = np.apply_over_axes(np.sum, array, 0)\n",
    "    row = np.apply_over_axes(np.sum, array, 1)\n",
    "    expected_frequencies = []\n",
    "    \n",
    "    for i in range(0, len(row)):\n",
    "        \n",
    "        for j in range(0, len(column)):\n",
    "            exp = (column[j] * row[i]) / np.sum(array)\n",
    "            \n",
    "        expected_frequencies.append(exp)\n",
    "    exp_freq = np.array(expected_frequencies)\n",
    "        \n",
    "    result = pd.DataFrame(exp_freq)\n",
    "        \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><p><b>c)</b> Write a function <b>computeChiSquare(M)</b> that receives a 2D numpy array with two discrete columns and computes the χ2 score of the two attributes.</p></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeChiSquare(M):\n",
    "    chi_square = np.sum(M ** 2 / expected_values)\n",
    "    \n",
    "    return(np.apply_over_axes(np.sum, chi_square, 0)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><p><b>d)</b> Write a function <b>checkIndependence(df, c1, c2, alpha)</b> that receives a Pandas DataFrame and the names of two columns and that returns true if the independence hypothesis is sustained in a χ2 test (considering the appropriate degree of freedom) for a given confidence threshold α for the p-value.\n",
    "</p></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIndependence(df, c1, c2, alpha):\n",
    "    contingency_table = getContingencyTable(df[[c1, c2]].to_numpy())\n",
    "    expected_values = computeExpectedOccurrences(contingency_table)\n",
    "    table = np.absolute(contingency_table - expected_values)\n",
    "    chi_2 = computeChiSquare(table)\n",
    "    degrees_of_freedom = (table.shape[0] - 1) * (table.shape[1] - 1)\n",
    "    chi2.median(degrees_of_freedom)\n",
    "    chi2.cdf(chi_2, degrees_of_freedom)\n",
    "    chi2.sf(chi_2, degrees_of_freedom)\n",
    "    chi2.ppf(alpha, degrees_of_freedom)\n",
    "    \n",
    "    return(chi2.sf(chi_2, degrees_of_freedom) > alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><p><b>e)</b> Then check independence hypothesis for all pairs of categorical variables of the credit dataset. Plot the χ2 curve for every pair of categorical variables with the respective (given) critical point (we assume α = 0.01).</p></li>\n",
    "<p>Are there pairs of independent variables?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'expected_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-71f843ac4a13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../credits.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-71f843ac4a13>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(df, alpha)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mindependent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckIndependence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-3be3cebcc0be>\u001b[0m in \u001b[0;36mcheckIndependence\u001b[0;34m(df, c1, c2, alpha)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mexpected_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputeExpectedOccurrences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontingency_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontingency_table\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mexpected_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mchi_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputeChiSquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdegrees_of_freedom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mchi2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegrees_of_freedom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-34b2251b8331>\u001b[0m in \u001b[0;36mcomputeChiSquare\u001b[0;34m(M)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcomputeChiSquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mchi_square\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mexpected_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_over_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchi_square\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'expected_values' is not defined"
     ]
    }
   ],
   "source": [
    "def plot(df, alpha):\n",
    "    atributes = getCategoricalAttributes(df)\n",
    "\n",
    "    for i, c1 in enumerate(atributes):\n",
    "        for j, c2 in enumerate(atributes):\n",
    "            independent = checkIndependence(df, c1, c2, alpha)\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(111)\n",
    "            contingency_table = getContingencyTable(df[[c1, c2]].to_numpy())\n",
    "            expected_values = computeExpectedOccurrences(contingency_table)\n",
    "            table = np.absolute(contingency_table - expected_values)\n",
    "            degrees_of_freedom = (table.shape[0] - 1) * (table.shape[1] - 1)\n",
    "            x = np.linspace(chi2.ppf(0.01,degrees_of_freedom),chi2.ppf(0.999, degrees_of_freedom), 100)\n",
    "            ax.plot(x, chi2.pdf(x, degrees_of_freedom))\n",
    "            ppf95 = chi2.ppf(1-alpha,degrees_of_freedom)\n",
    "            ax.plot([ppf95,ppf95], [0,chi2.pdf(ppf95, degrees_of_freedom)])\n",
    "            ax.set_title(c1 + ' vs ' + c2)\n",
    "            print(c1 + ' vs ' + c2 + ' are independent: ' + str(independent))\n",
    "            \n",
    "            \n",
    "    \n",
    "    return()\n",
    "\n",
    "\n",
    "plot(pd.read_csv(\"../credits.csv\"), 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback\n",
    "##  Exercise 1\n",
    "1. no suficientemente preciso. Por qué es $s \\leq d$? 0.5/1\n",
    "2. así no funciona. Tienen que comparar las distancias de los mismos puntos *categóricos* $x_1$ y $x_2$ bajo de dos codificaciones *diferentes*. 0.25/1\n",
    "\n",
    "## Exercise 2\n",
    "1. ok\n",
    "2. faltan unos aspectos y lo qué está, tampoco funcion al 100%. 0.75/2\n",
    "3. contingencias y expectativas bien, el cálculo de $\\chi^2$ es raro, por qué usan `expected_values`, qué no está definido dentro de la función. Falta también la discusión. De resto lo veo ok. 1.25/2\n",
    "\n",
    "Total: 0.75 + 4 = 4.75/8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
