{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Buisness Intelligence - Sheet 2 </h1>\n",
    "<h2> Camilo Andrés Vega Agudelo - 0000163913 </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Exercise 1.3 </h3>\n",
    "<p>  Covariances and Correlation after Normalization Techniques.\n",
    "    <ul>\n",
    "        <li>Robustness of Normalization towards linear feature transformations. Suppose we have some dataset D with sample covariance matrix Σˆ. Now suppose that we multiply each column of D with some number αi; call this new dataset D′. Show that the covariances of D and D′ are generally not identical. Then show, for both normalization techniques, that the covariance matrices we obtain after normalizing are the same for D and D′.\n",
    "        </li>\n",
    "        <li>Normalization preserves linear dependencies. Show that none of the normalization techniques changes the correlation coefficient between any two attributes.</li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Exercise 2.2 </h3>\n",
    "<p>\n",
    "    Implement two functions <b>normalize(D)</b> and <b>standardize(D)</b>, one to range-normalize and one to z-score-standardize a given matrix D (nparray; output should be a matrix too). Create a normalized and a standardized copy of the Iris data. Check the correlation matrices to see whether the linear dependency among attributes changes by normaliza- tion or standardization. In the two copies, find, respectively, the pair of attributes with the lowest and with the strongest covariance.\n",
    " </p>\n",
    " <p> \n",
    "    <i>Made by Camilo Vega</i> \n",
    " </p>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris_dataset = pd.read_csv('https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv')\n",
    "iris_without_species = iris_dataset.drop(columns=['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2\n",
    "\n",
    "# def normalize(D, att, xi):\n",
    "#     myRange = np.ptp(D[att])\n",
    "#     minValue = np.amin(D[att])\n",
    "#     x = D[att][xi]\n",
    "#     return((x-minValue)/myRange)\n",
    "\n",
    "# normalize(iris_dataset, 'sepal_length', 0)\n",
    "\n",
    "def normalize(D):\n",
    "    return((D - D.min(axis = 0)) / (D.max(axis = 0) - D.min(axis = 0)))\n",
    "\n",
    "def standardize(D):\n",
    "    return((D - D.mean(axis = 0)) / D.std(axis = 0))\n",
    "\n",
    "normalized_iris = normalize(iris_without_species)\n",
    "standarized_iris = standardize(iris_without_species)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
