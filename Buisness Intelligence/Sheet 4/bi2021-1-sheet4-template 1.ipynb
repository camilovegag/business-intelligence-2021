{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Unit Test for 1\n",
    "\n",
    "def testImputation(filename, nasymbol, incompletePoint, expectedCompletion):\n",
    "    df = read_csv(filename, nasymbol)[:10000]\n",
    "    colsWithQuestionMark = []\n",
    "    for col in df:\n",
    "        for val in df[col]:\n",
    "            if nasymbol in str(val):\n",
    "                colsWithQuestionMark.append(str(col))\n",
    "                break\n",
    "    print(\"Replacement: \" + (\"ok\" if len(colsWithQuestionMark) == 0 else (\" FAILED. The following columns have a missing symbol \\\"\" + str(nasymbol) + \"\\\": \" + str(colsWithQuestionMark))))\n",
    "\n",
    "    # check imputed neighbor\n",
    "    actNN = getNearestNeighbor(df.dropna(), incompletePoint)\n",
    "    reqNN = expectedCompletion\n",
    "    nnOK = True\n",
    "    for index in range(len(reqNN)):\n",
    "        req = reqNN[index]\n",
    "        act = actNN[index]\n",
    "        if req != act:\n",
    "            print(\"Nearest neighbor does not coincide in position \" + str(index) + \". Expected \" + str(req) + \" but saw \" + str(act))\n",
    "            nnOK = False\n",
    "    if nnOK:\n",
    "        print(\"Nearest neighbor correctly identified. Now checking conversion to matrix.\")\n",
    "\n",
    "        # now compute the entirely imputed\n",
    "        M = readFrameAsMatrixImputed(df)\n",
    "        if type(M) != np.ndarray:\n",
    "            print(\"Output is not an np-array but \", type(M))\n",
    "        else:\n",
    "            hasNanEntries = False\n",
    "            for row in M:\n",
    "                if np.count_nonzero(row == str(np.nan)):\n",
    "                    hasNanEntries = True\n",
    "                    break\n",
    "            print(\"Imputation: \" + (\"ok\" if not hasNanEntries else \"failed. There are nan-entries\"))\n",
    "\n",
    "## check for this incomplete point that the correct nearest neighbor is computed\n",
    "filename = \"credits.csv\"\n",
    "incompletePoint = pd.read_csv(filename).iloc[4,:]\n",
    "print(incompletePoint)\n",
    "reqNN = [27, ' Private', 103524, \" HS-grad\", 9, \" Never-married\", \" Handlers-cleaners\", \" Unmarried\", \" White\", \" Male\", 0, 0, 35, \" United-States\", \" <=50K\"]\n",
    "testImputation(filename, \" ?\", incompletePoint, reqNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 0.5\n",
      "Outcome size: OK\n",
      "max of age: OK\n",
      "min of age: OK\n",
      "max of fnlwgt: OK\n",
      "min of fnlwgt: OK\n",
      "max of education-num: OK\n",
      "min of education-num: OK\n",
      "max of capital-gain: OK\n",
      "min of capital-gain: OK\n",
      "max of capital-loss: OK\n",
      "min of capital-loss: OK\n",
      "max of hours-per-week: OK\n",
      "min of hours-per-week: OK\n",
      "k = 1\n",
      "Outcome size: OK\n",
      "max of age: OK\n",
      "min of age: OK\n",
      "max of fnlwgt: OK\n",
      "min of fnlwgt: OK\n",
      "max of education-num: OK\n",
      "min of education-num: OK\n",
      "max of capital-gain: OK\n",
      "min of capital-gain: OK\n",
      "max of capital-loss: OK\n",
      "min of capital-loss: OK\n",
      "max of hours-per-week: OK\n",
      "min of hours-per-week: OK\n",
      "k = 2\n",
      "Outcome size: FAIL. Expected 18803 but saw 18806\n",
      "max of age: OK\n",
      "min of age: OK\n",
      "max of fnlwgt: OK\n",
      "min of fnlwgt: OK\n",
      "max of education-num: OK\n",
      "min of education-num: OK\n",
      "max of capital-gain: OK\n",
      "min of capital-gain: OK\n",
      "max of capital-loss: OK\n",
      "min of capital-loss: OK\n",
      "max of hours-per-week: OK\n",
      "min of hours-per-week: OK\n"
     ]
    }
   ],
   "source": [
    "def testOutlierRemoval(df, expected_rows):\n",
    "    numeric_columns = list(df.select_dtypes(include=np.number).columns)\n",
    "    for k in [0.5, 1, 2]:\n",
    "        print(\"k = \" + str(k))\n",
    "        dfReduced = removeOutliers(df, k)\n",
    "        print(\"Outcome size: \" + (\"OK\" if len(dfReduced) == expected_rows[str(k)] else \"FAIL. Expected \" + str(expected_rows[str(k)]) + \" but saw \" + str(len(dfReduced))))\n",
    "        for col in numeric_columns:\n",
    "            vals = dfReduced[col].values\n",
    "            q75, q25 = np.percentile(vals, [75 ,25])\n",
    "            print(\"max of \" + col + \": \" + (\"OK\" if max(vals) <= q75 + k * (q75-q25) else \"FAIL\"))\n",
    "            print(\"min of \" + col + \": \" + (\"OK\" if min(vals) >= q25 - k * (q75-q25) else \"FAIL\"))\n",
    "\n",
    "testOutlierRemoval(pd.read_csv(\"credits.csv\"), {\"0.5\": 901, \"1\": 14781, \"2\": 18803})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumericalAttributes(df):\n",
    "    return list(df.select_dtypes(exclude=[object]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumericalAttributes(df):\n",
    "    return list(df.select_dtypes(exclude=[object]))\n",
    "\n",
    "def createBoxPlots(D):\n",
    "    iqrMultipliers = [0.25, 0.5, 1, 1.5, 2]\n",
    "    numericalAtts = getNumericalAttributes(D)\n",
    "    d = len(numericalAtts)\n",
    "    \n",
    "    for i in numericalAtts:\n",
    "        fig, ax = plt.subplots(1,5, figsize=(20,5))\n",
    "        for j, whis in enumerate(iqrMultipliers):\n",
    "            col = D[i]        \n",
    "            ax[j].set_title(i)\n",
    "            ax[j].yaxis.set_ticks_position('none')\n",
    "            ax[j].grid(color='grey', axis='y', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "            ax[j].set_xlabel('whisker at ' + str(whis))\n",
    "            ax[j].boxplot(col, whis=whis)  \n",
    "            fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeOutliers(D, k):\n",
    "    \n",
    "    row_length = D.shape[0]\n",
    "    if row_length == 0:\n",
    "        return D\n",
    "    \n",
    "    numericalAtts = getNumericalAttributes(D)\n",
    "\n",
    "    trues = np.array([True] * row_length)\n",
    "    for i in numericalAtts:\n",
    "        col = D[i]  \n",
    "        iqr = np.subtract(*np.percentile(col, [75, 25]))\n",
    "        q3 = np.percentile(col, [75])\n",
    "        q1 = np.percentile(col, [25])\n",
    "        above = np.array(col)<=(q3[0] + k*iqr)\n",
    "        below = np.array(col)>=(q1[0] - k*iqr)\n",
    "        trues = trues & above & below\n",
    "\n",
    "    conditioned = pd.DataFrame(D[trues])\n",
    "    final_frame = conditioned.reset_index(drop = True)\n",
    "    final_row_length = final_frame.shape[0]\n",
    "    \n",
    "    if final_row_length!= row_length:\n",
    "        return removeOutliers(final_frame, k)\n",
    "    else:\n",
    "        return final_frame\n",
    "    return final_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def testCorrelationRemoval(df, tau, expected_cols):\n",
    "    dfNumeric = df.select_dtypes(include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64'])\n",
    "    DReduced = eliminateCorrelations(dfNumeric.values, tau)\n",
    "    cors = np.abs(np.corrcoef(DReduced,rowvar=False))\n",
    "    cors = [cors[i,j] for i in range(len(cors)) for j in range(i)]\n",
    "    \n",
    "    print(\"Filter Success: \" + (\"OK\" if max(cors) < tau else \"FAIL. There is a pair with correlation \" + str(max(cors)) + \" > \" + str(tau)))\n",
    "    print(\"Shape: \" + (\"OK\" if (len(DReduced) == len(dfNumeric)) & (DReduced.shape[1] == expected_cols) else \"FAIL\"))\n",
    "\n",
    "testCorrelationRemoval(pd.read_csv(\"credits.csv\"), 0.1, expected_cols=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
